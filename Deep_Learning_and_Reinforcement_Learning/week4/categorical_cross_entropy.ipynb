{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"300\" alt=\"cognitiveclass.ai logo\">\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Categorical Cross-Entropy Loss**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **45** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we are going to use the MNIST hand-written digits dataset as a motivating example to understand categorical cross-entropy loss.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> House Number Detection </h1></s>\n",
    "\n",
    "You have been tasked with building a model that can recognize house numbers from arbitrary street-view images. You are given a set of images of single-digit house numbers engraved into slates or wall surfaces. The images vary in size and color. In this lab, we are going to use the MNIST hand-written digits dataset as a motivating example to understand the __softmax function__, __one-hot encoding__, and __categorical cross-entropy loss__. The MNIST hand-written dataset has 10 classes, each representing a digit from 0-9. We will attempt to build a multi-class classification model that will identify which digit is present in the image. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML311-Coursera/labs/Module3/L1/house_number.jpg\" style=\"width: 30%\">\n",
    "\n",
    "<!-- Original Source: https://slate.com/human-interest/2020/06/a-quest-to-catalogue-every-single-house-number-in-one-suburban-zip-code.html --> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Table of Contents**\n",
    "\n",
    "<ol>\n",
    "    <li><a href=\"https://#Objectives\">Objectives</a></li>\n",
    "    <li><a href=\"https://#Datasets\">Datasets</a></li>\n",
    "    <li>\n",
    "        <a href=\"https://#Setup\">Setup</a>\n",
    "        <ol>\n",
    "            <li><a href=\"https://#Installing-Required-Libraries\">Installing Required Libraries</a></li>\n",
    "            <li><a href=\"https://#Importing-Required-Libraries\">Importing Required Libraries</a></li>\n",
    "            <li><a href=\"https://#Defining-Helper-Functions\">Defining Helper Functions</a></li>\n",
    "        </ol>\n",
    "    </li>\n",
    "    <li><a href=\"https://https://#Categorical Cross-Entropy\">Categorical Cross-Entropy</a>\n",
    "        <ol>\n",
    "            <li><a href=\"https://#Softmax Activation Function\">Softmax Activation Function</a></li>\n",
    "            <li><a href=\"https://#One-Hot Encoding\">One-Hot Encoding</a></li>\n",
    "            <li><a href=\"#Categorical Cross-Entropy\">Categorical Cross-Entropy</a></li>\n",
    "        </ol>\n",
    "    </li>\n",
    "    <li><a href=\"https://#Binary vs. Multi-Class Classification\">Binary vs. Multi-Class Classification</a>\n",
    "        <ol>\n",
    "            <li><a href=\"https://#Binary Classification\">Binary Classification</a></li>\n",
    "            <li><a href=\"https://#Multi-Class Classification\">Multi-Class Classification</a></li>\n",
    "        </ol>\n",
    "    </li>\n",
    "    <li>\n",
    "        <a href=\"https://#Example: MNIST Hand-Written Digits\">Example: MNIST Hand-Written Digits</a> </li>\n",
    "    <li>\n",
    "        <a href=\"https://#Example: Single-Digit House Number Recognition\"> Example: Single-Digit House Number Recognition</a> </li>\n",
    "    <li><a href=\"https://#Exercises\">Exercises</a>\n",
    "        <ol>\n",
    "            <li><a href=\"https://#Exercise 1 - Loading and plotting the images\">Exercise 1 - Loading and plotting the images</a></li>\n",
    "            <li><a href=\"https://#Exercise 2 - Preparing the data\">Exercise 2 - Preparing the data</a></li>\n",
    "            <li><a href=\"https://#Exercise 3 - One-hot encoding\">Exercise 3 - One-hot encoding</a></li>\n",
    "            <li><a href=\"https://#Exercise 4 - Build model architecture\">Exercise 4 - Build model architecture</a></li>\n",
    "            <li><a href=\"https://#(Optional) Exercise 5 - Sparse Categorical Cross-Entropy\">Sparse Categorical Cross-Entropy</a></li>\n",
    "        </ol>\n",
    "    </li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "After completing this lab you will be able to:\n",
    "\n",
    "*   **Understand** what categorical cross-entropy is, and how it works with the Softmax activation function.\n",
    "*   **Build** simple CNN models for binary and multi-class classification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab, we will be using the following libraries:\n",
    "\n",
    "*   [`pandas`](https://pandas.pydata.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for managing the data.\n",
    "*   [`numpy`](https://numpy.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for mathematical operations.\n",
    "*   [`sklearn`](https://scikit-learn.org/stable/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for machine learning and machine-learning-pipeline related functions.\n",
    "*   [`seaborn`](https://seaborn.pydata.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for visualizing the data.\n",
    "*   [`matplotlib`](https://matplotlib.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for additional plotting tools.\n",
    "*   [`keras`](https://keras.io/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for loading datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Required Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "from PIL import Image\n",
    "from urllib.request import urlopen\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_multiclass_blobs(num_samples_total, training_split, cluster_centers, num_classes, loss_function_used):\n",
    "    X, targets = make_blobs(n_samples = num_samples_total, centers = cluster_centers, n_features = num_classes, center_box=(0, 1), cluster_std = 1.5)\n",
    "    categorical_targets = to_categorical(targets)\n",
    "    X_training = X[training_split:, :]\n",
    "    X_testing = X[:training_split, :]\n",
    "    Targets_training = categorical_targets[training_split:]\n",
    "    Targets_testing = categorical_targets[:training_split].astype(np.int32)\n",
    "    return X_training, Targets_training, X_testing, Targets_testing\n",
    "\n",
    "\n",
    "def generate_binary_blobs(num_samples_total, training_split, loss_function_used):\n",
    "    X, targets = make_blobs(n_samples = num_samples_total, centers = [(0,0), (15,15)], n_features = 2, center_box=(0, 1), cluster_std = 2.5)\n",
    "    targets[np.where(targets == 0)] = -1\n",
    "    X_training = X[training_split:, :]\n",
    "    X_testing = X[:training_split, :]\n",
    "    Targets_training = targets[training_split:]\n",
    "    Targets_testing = targets[:training_split]\n",
    "    return X_training, Targets_training, X_testing, Targets_testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Cross-Entropy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working on a machine learning problem, we use loss functions to optimize our models during training where a common objective is to minimize the loss function.\n",
    "\n",
    "Cross-entropy is a widely used loss or cost function, that is used to optimize classification models. Before delving into cross-entropy, let us first cover the prerequisites by learning about a common activation function called Softmax.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax Activation Function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activation functions are transformations applied to the output from CNNs before loss computations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Softmax activation function is typically placed as the last layer in a neural network and used to normalize the output of a network to a probability distribution over predicted output classes.\n",
    "\n",
    "It does so by scaling numbers/logits into probabilities for each possible outcome or class present in our dataset. The resulting probabilities in the vector sum up to one.\n",
    "\n",
    "Mathematically, Softmax is defined as follows:\n",
    "\n",
    "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML311-Coursera/labs/Module3/L1/softmax.png\" style=\"width: 30%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, $\\overrightarrow{{z}}$ is an input vector to the Softmax function $\\sigma$.\n",
    "\n",
    "$\\overrightarrow{{z}}\\_i$ represents the $i$th element of the input vector, and can take on values from -inf to inf.\n",
    "\n",
    "$\\overrightarrow{{z}}_i$ represents the $i$th element of the input vector, and can take on values from -inf to inf. \n",
    "\n",
    "$e^{z_i}$ is a standard exponential function applied on the $i$th element of $z$, and the denominator is a normalizing term (L1-norm) to ensure the result is a valid probability distribution, that is, sums up to 1, and values are within the 0 - 1 range.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exponential is a steeply increasing function; that is, it increases the difference between outputs. In the final output, the largest element (which dominates the norm) is normalized to a value close to 1, while all the other elements end up being close to 0. Not only does the resulting vector show the winning class, but it also retains the original order of values.\n",
    "\n",
    "\n",
    "Another important point to note is that Softmax is not affected by negative values, as the exponent of any value is always a positive value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us walk through an example to understand Softmax.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine you are building a CNN model to classify an image as a dog, cat, fish, or horse. The fully-connected layer of your CNN gives a vector of logits. You pass the vector through the Softmax function above to obtain probabilities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML311-Coursera/labs/Module3/L1/cce_diag.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ground truth is typically presented in form of categorical data; that is, a given image is categorized into one of these classes: dog, cat, fish, or horse.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For categorical variables where no ordinal relationships exist, we can perform one-hot encoding to represent each class. This is best explained through an example.\n",
    "\n",
    "In our case, we will have four classes, and these are the corresponding one-hot encoded labels:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML311-Coursera/labs/Module3/L1/ohe_labels.png\" style=\"width: 50%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in one-hot encoding, we represent labels with a binary variable where for every given class, we have the value 1 for the position corresponding to that particular class and 0 elsewhere (that is, 100% probability of belonging to that class).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back to Categorical Cross-Entropy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have converted the logits to output probabilities, we need to measure how good they are; that is, measure the distance from the truth values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, in the example above, the desired output is [1,0,0,0], but the model outputs [0.775,0.116,0.039,0.070].\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The categorical cross-entropy is mathematically defined as follows:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML311-Coursera/labs/Module3/L1/cce.png\" style=\"width: 30%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the formula above to compute the cross-entropy loss. When training our model, we iteratively update the weights to minimize the cross-entropy loss. \n",
    "\n",
    "The Softmax is continuously differentiable, and this property makes it easy to compute the derivative of the loss function and, accordingly, adjust the model weights in each iteration to minimize the loss function.\n",
    "\n",
    "In the next iteration, if our $$L\\_{CE}$$ is lower than the current one, we say that the model is *learning*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary vs. Multi-Class Classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us do a quick review of binary and multi-class classification. Binary classification tasks require that all examples be assigned to one of two classes, whereas in multi-class classification, examples can belong to more than two classes.\n",
    "\n",
    "For binary classification problems, we have a final layer with a single node and a sigmoid activation function. It can map the output vector from a CNN to values between 0 and 1 before loss computations. The sigmoid function is denoted using the following formula:\n",
    "\n",
    "$$\\sigma(x) = 1/(1+e^{-x})$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see binary classification and multi-class classification in action.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a helper function defined at the beginning of the notebook, we will use the `make_blobs()` function from `sklearn` to generate isotropic Gaussian blobs for classification.\n",
    "\n",
    "We will create a data set with 1000 samples, and use 750 of those samples for training a simple CNN model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us define a few more configuration options.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us define a few more configuration options.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   **num_samples**: refers to the total number of samples in our dataset\n",
    "*   **test_split**: refers to the number of samples to be used for testing\n",
    "*   **cluster_centers**: we define 2 centers for our isotropic Gaussian blobs\n",
    "*   **num_classes**: we have 2 classes\n",
    "*   **loss_function_used**: since this is a binary classification problem, we use binary cross-entropy loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1000\n",
    "test_split = 250\n",
    "cluster_centers = [(15, 0), (30, 15)]\n",
    "num_classes = len(cluster_centers)\n",
    "loss_function_used = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, targets_train, X_test, targets_test = generate_binary_blobs(num_samples, test_split, loss_function_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4, 4))\n",
    "plt.scatter(X_train[:, 0], X_train[:, 0])\n",
    "plt.title(\"Linearly separable data\")\n",
    "plt.xlabel(\"x1\")\n",
    "plt.xlabel(\"x2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will build a simple CNN model with two hidden layers, that uses sigmoid as the activation function, and binary cross-entropy as the loss function. Let's define the architecture of our model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vector_shape = X_train.shape[1]\n",
    "input_shape = (feature_vector_shape, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mbarbaric/dev/ai_projects/IBM_Machine_Learning_Course/.venv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(12, input_shape=input_shape, activation='relu', kernel_initializer='he_uniform'),\n",
    "    tf.keras.layers.Dense(8, activation='relu', kernel_initializer='he_uniform'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mbarbaric/dev/ai_projects/IBM_Machine_Learning_Course/.venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/nn.py:674: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.4470 - loss: -3.8786 - val_accuracy: 0.4067 - val_loss: -60.5841\n",
      "Epoch 2/30\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4542 - loss: -132.8311 - val_accuracy: 0.4533 - val_loss: -645.0687\n",
      "Epoch 3/30\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5006 - loss: -875.3995 - val_accuracy: 0.4267 - val_loss: -2420.1116\n",
      "Epoch 4/30\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5035 - loss: -2721.3474 - val_accuracy: 0.4000 - val_loss: -6225.3936\n",
      "Epoch 5/30\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4535 - loss: -6814.4360 - val_accuracy: 0.4200 - val_loss: -12696.2021\n",
      "Epoch 6/30\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4787 - loss: -11787.0605 - val_accuracy: 0.4200 - val_loss: -22391.9648\n",
      "Epoch 7/30\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5081 - loss: -22235.7129 - val_accuracy: 0.4533 - val_loss: -35918.9414\n",
      "Epoch 8/30\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4870 - loss: -35603.0078 - val_accuracy: 0.4200 - val_loss: -53749.6914\n",
      "Epoch 9/30\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5173 - loss: -47797.8711 - val_accuracy: 0.4533 - val_loss: -75853.4531\n",
      "Epoch 10/30\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4906 - loss: -71017.9219 - val_accuracy: 0.4400 - val_loss: -102791.7656\n",
      "Epoch 11/30\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4683 - loss: -98451.5156 - val_accuracy: 0.4533 - val_loss: -134113.5156\n",
      "Epoch 12/30\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5047 - loss: -129859.2578 - val_accuracy: 0.4533 - val_loss: -171839.5625\n",
      "Epoch 13/30\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4754 - loss: -166177.0938 - val_accuracy: 0.4400 - val_loss: -213559.4375\n",
      "Epoch 14/30\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4770 - loss: -211654.1719 - val_accuracy: 0.4533 - val_loss: -262110.9375\n",
      "Epoch 15/30\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4987 - loss: -240537.7812 - val_accuracy: 0.4533 - val_loss: -315877.5312\n",
      "Epoch 16/30\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4613 - loss: -295477.3750 - val_accuracy: 0.4533 - val_loss: -377959.3125\n",
      "Epoch 17/30\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5148 - loss: -346919.2188 - val_accuracy: 0.4467 - val_loss: -444129.0000\n",
      "Epoch 18/30\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4722 - loss: -427448.5000 - val_accuracy: 0.4467 - val_loss: -517536.7500\n",
      "Epoch 19/30\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4897 - loss: -438790.4375 - val_accuracy: 0.4533 - val_loss: -597955.1875\n",
      "Epoch 20/30\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4988 - loss: -547862.1875 - val_accuracy: 0.4533 - val_loss: -685226.0000\n",
      "Epoch 21/30\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5095 - loss: -621317.3750 - val_accuracy: 0.4533 - val_loss: -777551.8125\n",
      "Epoch 22/30\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5090 - loss: -701526.4375 - val_accuracy: 0.4533 - val_loss: -881019.4375\n",
      "Epoch 23/30\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4833 - loss: -849136.3125 - val_accuracy: 0.4533 - val_loss: -988775.8125\n",
      "Epoch 24/30\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4804 - loss: -935957.8750 - val_accuracy: 0.4533 - val_loss: -1105382.7500\n",
      "Epoch 25/30\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4851 - loss: -1050592.1250 - val_accuracy: 0.4467 - val_loss: -1224168.3750\n",
      "Epoch 26/30\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5070 - loss: -1082119.0000 - val_accuracy: 0.4467 - val_loss: -1352538.0000\n",
      "Epoch 27/30\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4674 - loss: -1274038.7500 - val_accuracy: 0.4533 - val_loss: -1491257.6250\n",
      "Epoch 28/30\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5104 - loss: -1238716.6250 - val_accuracy: 0.4533 - val_loss: -1636492.2500\n",
      "Epoch 29/30\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5019 - loss: -1439024.0000 - val_accuracy: 0.4533 - val_loss: -1789084.0000\n",
      "Epoch 30/30\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5119 - loss: -1468941.8750 - val_accuracy: 0.4467 - val_loss: -1950112.2500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fb3463080a0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=loss_function_used, optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), metrics=['accuracy'])\n",
    "model.fit(X_train, targets_train, epochs=30, batch_size=5, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now use the trained model to make predictions on an unseen test dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4721 - loss: -1695870.7500 \n",
      "Test results - loss: -1689143.125 - Accuracy: 49.59999918937683%\n"
     ]
    }
   ],
   "source": [
    "test_results = model.evaluate(X_test, targets_test)\n",
    "print(f\"Test results - loss: {test_results[0]} - Accuracy: {test_results[1] * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Targets_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plot_decision_regions(X_test, \u001b[43mTargets_test\u001b[49m, clf\u001b[38;5;241m=\u001b[39mmodel, legend\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Targets_test' is not defined"
     ]
    }
   ],
   "source": [
    "plot_decision_regions(X_test, targets_test, clf=model, legend=2)\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
