{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\">\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Regularization Techniques**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **30** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will learn five regularization techniques that are commonly used in training neural networks. You will see how they are implemented using Keras and the result of applying each of them on a real world dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "<ol>\n",
    "    <li><a href=\"https://#Objectives\">Objectives</a></li>\n",
    "    <li>\n",
    "        <a href=\"https://#Setup\">Setup</a>\n",
    "        <ol>\n",
    "            <li><a href=\"#Installing-Required-Libraries\">Installing Required Libraries</a></li>\n",
    "            <li><a href=\"#Importing-Required-Libraries\">Importing Required Libraries</a></li>\n",
    "            <li><a href=\"#Defining-Helper-Functions\">Defining Helper Functions</a></li>\n",
    "        </ol>     \n",
    "    </li>\n",
    "    <li><a href=\"https://#Overfitting\">Overfitting</a></li>\n",
    "    <li><a href=\"https://#L2-Regularization\">L2 Regularization</a></li> \n",
    "    <li><a href=\"https://#L1-Regularization\">L1 Regularization</a></li>\n",
    "    <li><a href=\"https://#Dropout\">Dropout</a></li> \n",
    "    <li><a href=\"https://#Batch-Normalization\">Batch Normalization</a></li>\n",
    "    <li><a href=\"#Example 1: Apply regularization techniques on simulated data\">Example 1: Apply regularization techniques on simulated data</a></li>\n",
    "    <li><a href=\"#Example 2: Spam Classification\">Example 2: Spam Classification</a></li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "After completing this lab you will be able to:\n",
    "\n",
    "*   Understand how the regularization techniques (L1, L2, Dropout, BatchNorm) work for neural networks.\n",
    "*   Describe the difference between L1 and L2 regularization.\n",
    "*   Apply the four types of regularization when training neural networks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab, we will be using the following libraries:\n",
    "\n",
    "*   [`numpy`](https://numpy.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for mathematical operations.\n",
    "*   [`Pillow`](https://pillow.readthedocs.io/en/stable/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for image processing functions.\n",
    "*   [`OpenCV`](https://docs.opencv.org/4.x/index.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for other image processing functions.\n",
    "*   [`tensorflow`](https://www.tensorflow.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for machine learning and neural network related functions.\n",
    "*   [`matplotlib`](https://matplotlib.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for additional plotting tools.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing Required Libraries\n",
    "\n",
    "The following required libraries are pre-installed in the Skills Network Labs environment. However, if you run these notebook commands in a different Jupyter environment (like Watson Studio or Anaconda), you will need to install these libraries by removing the `#` sign before `!mamba` in the following code cell.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Required Libraries\n",
    "\n",
    "*We recommend you import all required libraries in one place, as follows:*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/mbarbaric/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Helper Functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function helps prepare the SMS Spam dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data():\n",
    "    try:\n",
    "        data = pd.read_csv(\"spam.csv\", encoding='latin-1')\n",
    "    except FileNotFoundError:\n",
    "        print(\"Data file not found, make sure it's downloaded.\")\n",
    "        \n",
    "    data.drop(['Unnamed: 2','Unnamed: 3','Unnamed: 4'], axis=1, inplace=True)\n",
    "    data.rename(columns={\"v1\": \"label\", \"v2\": \"text\"}, inplace=True)\n",
    "    data.label = data['label'].map({'ham':0, 'spam':1})\n",
    "    data['Count'] = data['text'].apply(lambda x: len(x))\n",
    "    \n",
    "    sw=stopwords.words(\"english\")\n",
    "    vectorizer = TfidfVectorizer(stop_words=sw, binary=True)\n",
    "\n",
    "    X = vectorizer.fit_transform(data.text).toarray()\n",
    "    y = data.label\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function plots the loss and accuracy curve from the training history of a neural network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(history):\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    for i, metric in enumerate(['accuracy', 'loss']):\n",
    "        train_metrics = history.history[metric]\n",
    "        val_metrics = history.history['val_'+metric]\n",
    "        epochs = range(1, len(train_metrics) + 1)\n",
    "        plt.subplot(1,2,i+1)\n",
    "        plt.plot(epochs, train_metrics)\n",
    "        plt.plot(epochs, val_metrics)\n",
    "        plt.title('Training and validation '+ metric)\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(metric)\n",
    "        plt.legend([\"train_\"+metric, 'val_'+metric])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In the following figure, we see a two-class classification problem. The red points represent one class, and the blue points represent the second class. The actual decision boundary is shown in black. Most points are in the correct region, but several samples are in the incorrect region; this could be for many reasons, such as noise or outliers. The key point is that you do not expect data points of these classes in these regions.\n",
    "\n",
    "The second model in green is meant to approximate the decision boundary; this model classifies the data points, even the data points in the incorrect regions. This model does not generalize well. This is because most data points will not be in those regions. As a result, the data will do poorly on data not from the original dataset, like data in the real world. This is called **overfitting**.\n",
    "\n",
    "<center><img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML311-Coursera/labs/Module1/L3/images/Overfitting.png\" width=\"40%\"></center>\n",
    "\n",
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://en.wikipedia.org/wiki/Overfitting\">Source: Wikipedia</a>\n",
    "</p>\n",
    "\n",
    "To combat overfitting or high variance, we introduce four regularization techniques in this lab for you to choose from the next time you train your neural network. They are:\n",
    "\n",
    "- L2 (Ridge) regularization\n",
    "- L1 (Lasso) regularization\n",
    "- Dropout\n",
    "- Batch Normalization \n",
    "- Data shuffling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2 Regularization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L2 regularization is perhaps the most common form of regularization analogous to the penalty term in  **Ridge regression**. It penalizes the squared magnitude of the weights $\\boldsymbol w$ by adding the term $\\frac12 \\lambda w^2$ to the objective function that the algorithm is trying to optimize. $\\lambda$ is the regularization strength, also called the **shrinkage parameter** which can be tuned during training. \n",
    "\n",
    "The regularization term is defined as the Euclidean norm of the weight matrices, which sums over all the squared weights. It is multiplied by $\\frac12$ so that when the gradient is calculated we get $\\lambda w$.\n",
    "\n",
    "As the shrinkage parameter approaches infinity, the weights are driven down to near zero but **will not be exactly zero**. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using L2 Regularization in Keras\n",
    "\n",
    "In Keras, regularization penalties are applied on a per-layer basis, that is, you specify the name of the regularizer API as you add a layer to the network. The `tf.keras.regularizers` module has a built-in L2 class that you can call using the following:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.regularizers.l2(l=0.01) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_layer = Dense(\n",
    "    32,\n",
    "    activation=\"relu\",\n",
    "    kernel_regularizer=tf.keras.regularizers.l2(l=0.01)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
