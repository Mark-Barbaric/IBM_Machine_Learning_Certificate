{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork821-2023-01-01\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Gaussian Mixture Models**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **45** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use cases of GMM:\n",
    "\n",
    "- **Recommender systems** that make recommendations to users based on preferences (such as Netflix viewing patterns) of similar users (such as neighbors).\n",
    "- **Anomaly detection** that identifies rare items, events or observations which deviate significantly from the majority of the data and do not conform to a well defined notion of normal behavior.\n",
    "- **Customer segmentation** that aims at separating customers into multiple clusters, and devise targeted marketing strategy based on each cluster's characteristics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When is GMM better than K-Means?\n",
    "\n",
    "Imagine you are a Data Scientist who builds a recommender for selling cars using K-Means clustering and you have two clusters. Everybody in cluster A is recommended to buy car A, which costs **100k** with a **25k** profit margin, and everyone in cluster B is recommended to buy car B, which costs **50k** with a **10k** profit margin.\n",
    "\n",
    "Let's say you want to get as many people in cluster A as possible, why not use an algorithm that informs you of exactly how likely somebody would be interested in purchasing car A, instead of one that only tells you a hard yes or no (This is what K-Means does!). \n",
    "\n",
    "With GMM, not only will you be getting the predicted cluster labels, the algorithm will also give you the probability of a data point belonging to a cluster. How amazing is that! \n",
    "\n",
    "Whoever, is selling those cars should definitely work on a better plan for a customer with a 90% chance of purchasing, than for someone with a 75% chance of purchasing, even though they might show up in the same cluster.\n",
    "\n",
    "\n",
    "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML0187EN-SkillsNetwork/labs/module%201/images/car.png\" style=\"width: 60%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will be applying clustering analysis on multivariate datasets using **Gaussian Mixture Models** (GMM).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Table of Contents__\n",
    "\n",
    "<ol>\n",
    "    <li><a href=\"#Objectives\">Objectives</a></li>\n",
    "    <li>\n",
    "        <a href=\"#Setup\">Setup</a>\n",
    "        <ol>\n",
    "            <li><a href=\"#Installing-Required-Libraries\">Installing Required Libraries</a></li>\n",
    "            <li><a href=\"#Importing-Required-Libraries\">Importing Required Libraries</a></li>\n",
    "            <li><a href=\"#Defining-Helper-Functions\">Defining Helper Functions</a></li>\n",
    "        </ol>\n",
    "    </li>\n",
    "    <li>\n",
    "        <a href=\"#What-are-Gaussian-Mixture-Models (GMM)?\">What are Gaussian Mixture Models (GMM)?</a>\n",
    "        <ol>\n",
    "            <li><a href=\"#Background\">Background</a></li>\n",
    "            <li><a href=\"#Playing around with means, standard deviations, and weights\">Playing around with means, standard deviations, and weights</a></li>\n",
    "            <li><a href=\"#Introducing sklearn.mixture.GaussianMixture\">Introducing sklearn.mixture.GaussianMixture</a></li>\n",
    "            <li><a href=\"#GMM.predict_proba\">GMM.predict_proba</a></li>\n",
    "        </ol>\n",
    "    </li>\n",
    "    <li>\n",
    "        <a href=\"#Example 1: Applying GMM on a 2d dataset\">Example 1: Applying GMM on a 2d dataset</a>\n",
    "        <ol>\n",
    "            <li><a href=\"#Generate an artificial 2d Gaussian mixture data\">Generate an artificial 2d Gaussian mixture data</a></li>\n",
    "            <li><a href=\"#Fit a GMM\">Fit a GMM</a></li>\n",
    "            <li><a href=\"#Plot the clusters\">Plot the clusters</a></li>\n",
    "            <li><a href=\"#Try different values of Covariance_type\">Try different values of Covariance_type</a></li>          \n",
    "        </ol>   \n",
    "    </li>\n",
    "    <li>\n",
    "        <a href=\"#Example 2: Applying GMM on real world data - Image Segmentation\">Example 2: Applying GMM on real world data - Image Segmentation</a>\n",
    "    </li>\n",
    "</ol>\n",
    "\n",
    "<a href=\"#Exercises\">Exercises</a>\n",
    "<ol>\n",
    "    <li><a href=\"#Exercise 1 - Scale the data (using StandardScaler)\">Exercise 1 - Scale the data (using StandardScaler)</a></li>\n",
    "    <li><a href=\"#Exercise 2 - Use PCA with n_components=2 for dimension reduction\">Exercise 2 - Use PCA with n_components=2 for dimension reduction</a></li>\n",
    "    <li><a href=\"#Exercise 3 - Fit a GMM to the reduced data \">Exercise 3 - Fit a GMM to the reduced data</a></li>\n",
    "    <li><a href=\"#Exercise 4 - Output the predicted labels for visualizing clusters\">Exercise 4 - Output the predicted labels for visualizing clusters</a></li>\n",
    "    <li><a href=\"#Exercise 5 - Clustering and visualizing using 3 principal components (OPTIONAL)\">Exercise 5 - Clustering and visualizing using 3 principal components (OPTIONAL)</a></li>\n",
    "</ol>\n",
    "\n",
    "## Objectives\n",
    "\n",
    "After completing this lab you will be able to:\n",
    "\n",
    "- __Understand__ what Gaussian mixture is and how its distribution parameters affect the prior probabilities.\n",
    "- __Understand__ what Gaussian mixture model is and how it works as a clustering technique.\n",
    "- __Apply__ GMM effectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab, we will be using the following libraries:\n",
    "\n",
    "*   [`pandas`](https://pandas.pydata.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for managing the data.\n",
    "*   [`numpy`](https://numpy.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for mathematical operations.\n",
    "*   [`sklearn`](https://scikit-learn.org/stable/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for machine learning and machine-learning-pipeline related functions.\n",
    "*   [`seaborn`](https://seaborn.pydata.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for visualizing the data.\n",
    "*   [`matplotlib`](https://matplotlib.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for additional plotting tools.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following required libraries are __not__ pre-installed in the Skills Network Labs environment. __You will need to run the following cell__ to install them:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Required Libraries\n",
    "\n",
    "_We recommend you import all required libraries in one place (here):_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Helper Functions\n",
    "\n",
    "_Use this section to define any helper functions to help the notebook's code readability:_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will allow us to easily plot data taking in x values, y values, and a title\n",
    "def plot_univariate_mixture(means, stds, weights, N = 10000, seed=10):\n",
    "    \n",
    "    \"\"\"\n",
    "    returns the simulated 1d dataset X, a figure, and the figure's ax\n",
    "    \n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    if not len(means)==len(stds)==len(weights):\n",
    "        raise Exception(\"Length of mean, std, and weights don't match.\") \n",
    "    K = len(means)\n",
    "    \n",
    "    mixture_idx = np.random.choice(K, size=N, replace=True, p=weights)\n",
    "    # generate N possible values of the mixture\n",
    "    X = np.fromiter((ss.norm.rvs(loc=means[i], scale=stds[i]) for i in mixture_idx), dtype=np.float64)\n",
    "      \n",
    "    # generate values on the x axis of the plot\n",
    "    xs = np.linspace(X.min(), X.max(), 300)\n",
    "    ps = np.zeros_like(xs)\n",
    "    \n",
    "    for mu, s, w in zip(means, stds, weights):\n",
    "        ps += ss.norm.pdf(xs, loc=mu, scale=s) * w\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(xs, ps, label='pdf of the Gaussian mixture')\n",
    "    ax.set_xlabel(\"X\", fontsize=15)\n",
    "    ax.set_ylabel(\"P\", fontsize=15)\n",
    "    ax.set_title(\"Univariate Gaussian mixture\", fontsize=15)\n",
    "    #plt.show()\n",
    "    \n",
    "    return X.reshape(-1,1), fig, ax\n",
    "    \n",
    "    \n",
    "def plot_bivariate_mixture(means, covs, weights, N = 10000, seed=10):\n",
    "    \n",
    "    \"\"\"\n",
    "    returns the simulated 2d dataset X and a scatter plot is shown\n",
    "    \n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    if not len(mean)==len(covs)==len(weights):\n",
    "        raise Exception(\"Length of mean, std, and weights don't match.\") \n",
    "    K = len(means)\n",
    "    M = len(means[0])\n",
    "    \n",
    "    mixture_idx = np.random.choice(K, size=N, replace=True, p=weights)\n",
    "    \n",
    "    # generate N possible values of the mixture\n",
    "    X = np.fromiter(chain.from_iterable(multivariate_normal.rvs(mean=means[i], cov=covs[i]) for i in mixture_idx), \n",
    "                dtype=float)\n",
    "    X.shape = N, M\n",
    "    \n",
    "    xs1 = X[:,0] \n",
    "    xs2 = X[:,1]\n",
    "    \n",
    "    plt.scatter(xs1, xs2, label=\"data\")\n",
    "    \n",
    "    L = len(means)\n",
    "    for l, pair in enumerate(means):\n",
    "        plt.scatter(pair[0], pair[1], color='red')\n",
    "        if l == L-1:\n",
    "            break\n",
    "    plt.scatter(pair[0], pair[1], color='red', label=\"mean\")\n",
    "    \n",
    "    plt.xlabel(\"$x_1$\")\n",
    "    plt.ylabel(\"$x_2$\")\n",
    "    plt.title(\"Scatter plot of the bivariate Gaussian mixture\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return X\n",
    "\n",
    "\n",
    "def draw_ellipse(position, covariance, ax=None, **kwargs):\n",
    "    \n",
    "    \"\"\"\n",
    "    Draw an ellipse with a given position and covariance\n",
    "    \n",
    "    \"\"\"\n",
    "    ax = ax or plt.gca()\n",
    "    \n",
    "    # Convert covariance to principal axes\n",
    "    if covariance.shape == (2, 2):\n",
    "        U, s, Vt = np.linalg.svd(covariance)\n",
    "        angle = np.degrees(np.arctan2(U[1, 0], U[0, 0]))\n",
    "        width, height = 2 * np.sqrt(s)\n",
    "    else:\n",
    "        angle = 0\n",
    "        width, height = 2 * np.sqrt(covariance)\n",
    "    \n",
    "    # Draw the Ellipse\n",
    "    for nsig in range(1, 4):\n",
    "        ax.add_patch(Ellipse(position, nsig * width, nsig * height, angle, **kwargs))\n",
    "        \n",
    "        \n",
    "def plot_gmm(gmm, X, label=True, ax=None):\n",
    "    ax = ax or plt.gca()\n",
    "    labels = gmm.fit(X).predict(X)\n",
    "    if label:\n",
    "        ax.scatter(X[:, 0], X[:, 1], c=labels, s=40, cmap='viridis', zorder=2)\n",
    "    else:\n",
    "        ax.scatter(X[:, 0], X[:, 1], s=40, zorder=2)\n",
    "    ax.axis('equal')\n",
    "    \n",
    "    w_factor = 0.2 / gmm.weights_.max()\n",
    "    for pos, covar, w in zip(gmm.means_, gmm.covariances_, gmm.weights_):\n",
    "        draw_ellipse(pos, covar, alpha=w * w_factor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are Gaussian Mixture Models (GMM)?\n",
    "\n",
    "Put simply, Gaussian Mixture Models (GMM) is a clustering algorithm that:\n",
    "\n",
    "- Fits a weighted combination of Gaussian distributions to your data\n",
    "- The data scientist (you) needs to determine the number of gaussian distributions (`k`)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='color: blue'>Hard vs Soft Clustering:</p>\n",
    "\n",
    "- __Hard clustering__ algorithms assign each data point to exactly one cluster.\n",
    "- __Soft clustering__ algorithms return probabilities of each data point belonging to all `k` clusters\n",
    "\n",
    "_GMM is a soft clustering algorithm._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Gaussian mixture is a weighted combination of (`k`) Gaussians, where each is identified by the following parameters:\n",
    "\n",
    " 1. a mean vector $\\boldsymbol{\\mu}_i$\n",
    " 2. a covariance matrix $\\boldsymbol{\\Sigma}_i$\n",
    " 3. a component weight $\\pi_i$ that indicates the contribution of the $i$th Gaussian\n",
    "\n",
    "When put altogether, the pdf of the mixture model is formulated as:\n",
    "\n",
    "$$\n",
    "p(\\boldsymbol{x}) = \\sum_{i=1}^K\\pi_i \\mathcal{N}(x|\\boldsymbol{\\mu_i,\\Sigma_i}), \\\\\\\\\\\\ \\sum_{i=1}^K\\pi_i = 1\n",
    "$$\n",
    "\n",
    "Before we start applying the model in a multivariate setting, let's delve into the three parameters and see how changing the parameter values affect the appearance of the Gaussian mixture in a lower dimension.\n",
    "\n",
    "_We will use the helper function **plot_univariate_mixture** to plot the mixture efficiently._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playing around with means, standard deviations, and weights\n",
    "\n",
    "Let's start with a mixture of 3 univariate Gaussians with \n",
    "- means equal to **2, 5, 8** respectively\n",
    "- std equal to **0.2, 0.5, 0.8** respectively\n",
    "- component weight equal to **0.3, 0.3, 0.4** respectively\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
