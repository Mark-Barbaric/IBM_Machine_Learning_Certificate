{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This workbook covers and demonstrates the theory behind Logistic Regression, including Gradient Descent and various Cost Functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Logistic Regression Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression is used to solve classification problems where the outcome is a discrete variable. Usually it is used to solve __Binary Classification__ problems.\\\n",
    "\\\n",
    "We utitilze the sigmoid function to map input values from a wide range into a limited interval using the below formula:\\\n",
    "\\\n",
    "$$ y = g(z) = \\frac {e^z} {1 + e^z} $$ \n",
    "\\\n",
    "This formula represents the probability of observing output y = 1 from a Bernoulli random variable. Essentially it squeezes and real number to the (0, 1) interval.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](images/logistic_activation_function.png)\n",
    "\n",
    "Applying the sigmoid function on 0 gives 0.5. The output becomes 1 as the input approaches \\inf. Conversely, sigmoid becomes 0 as the input approaches - \\inf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sigmoid function for the hypothesis is defined below:\n",
    "\n",
    "$$ h(x) = \\frac {1} {1 + e ^ -\\theta Tx} $$\n",
    "\n",
    "The hypothesis function approximates the estimated probability of the actual output being equal to 1: \n",
    "\n",
    "$$ p(y = 1 | \\theta, x) = g(z) = \\frac {1} {1 + e ^ -\\theta Tx} $$\n",
    "$$ p(y = 0 | \\theta, x) = 1 - g(z) = 1 - \\frac {1} {1 + e ^ -\\theta Tx} = \\frac {1} {1 + e ^ \\theta Tx} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Logistic Regression Cost Function\n",
    "\n",
    "__The cost function summarizes how well the model is behaving__. We use the cost function to measure how close the model's predictions are to the actual output. In linear regression, we use mean squared error as the cost function, but for Logistic Regression this may give a wavy non-convex solution with many local optima:\n",
    "\n",
    "![image.png](images/lr_with_mse.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, we use a logarithmic function to represent the cost of logistic regression. With __binary classification__ the logarithmic cost depends on the value of y:\n",
    "\n",
    "![image.png](images/lr_binary_classification_cost.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because when the actual output y = 1, the cost is 0 for ho(x) = 1 and 1 for ho(x) = 0.\n",
    "As the output is either 0 or 1, the equation can be simplified to: \n",
    "\n",
    "$$ cost(h\\theta(x), y) = -y ^ i \\times  \\log(h\\theta(x ^ i)) - (1 - t ^ i) \\times \\log(h\\theta(x^i)) $$\n",
    "\n",
    "And the m observations, we calculate the cost as:\n",
    "\n",
    "$$ J(\\theta) = - \\frac {1} {m}  \\sum_i^m [y ^ i \\times \\log(h\\theta(x ^ i)) + (1 - y ^ i) \\times \\log(h\\theta(x ^ i))] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Minimizing the Cost with Gradient Descent\n",
    "\n",
    "__Gradient Descent is an iterative optimization algorithm which finds the minimum of a differentiable function.__ In this process, we try different value and update them to find  the optimal ones. We can apply this method to the cost function of logistic regression, finding an optimal solution minimizing the cost over model parameters:\n",
    "$$ min J (\\theta) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume that we have a total of _n_ features. In this case, we have _n_ parameters for the $ \\theta $ vector. To minimize our cost function, we need to run the gradient descent on each parameter $ \\theta~j $:\n",
    "$$ \\theta_j \\larr \\theta_j - \\alpha \\frac {\\alpha} {\\alpha \\theta_j} J(\\theta) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, we need to update each parameter simultaneously for each iteration. To complete the full algorithm, we need the value of $ \\frac {\\alpha} {\\alpha \\theta_j} J(\\theta)$:\n",
    "$$ \\frac {\\alpha} {\\alpha \\theta_j} J(\\theta) = \\frac {1} {m}  \\sum_i^m (h_\\theta(x^i) - y^i) x_j^i $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plugging this back into the original Gradient Descent function gives the below:\n",
    "\n",
    "$$ \\theta_j \\larr \\theta_j - \\alpha \\frac {1} {m} \\sum_i^m (h_\\theta(x^i) - y^i) x_j^i $$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
